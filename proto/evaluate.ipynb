{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc4a90ea",
   "metadata": {},
   "source": [
    "# Evaluating branchrules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf25b078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fbc898",
   "metadata": {},
   "source": [
    "SeedSequence needs a `.spawn-one` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705f2f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng, SeedSequence\n",
    "\n",
    "\n",
    "def spawn_one(ss: SeedSequence) -> SeedSequence:\n",
    "    return ss.spawn(1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248b39ce",
   "metadata": {},
   "source": [
    "A function to add a dict record to a table (dict-of-lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0e99ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "\n",
    "def do_add(\n",
    "    record: dict, to: dict[..., list], transform: Callable[..., dict] = None\n",
    ") -> dict:\n",
    "    \"\"\"Add the record to a transposed dict of lists.\"\"\"\n",
    "    original = record\n",
    "    if callable(transform):\n",
    "        record = transform(**record)\n",
    "\n",
    "    # assume no fields are missing\n",
    "    for field, value in record.items():\n",
    "        to.setdefault(field, []).append(value)\n",
    "\n",
    "    return original\n",
    "\n",
    "\n",
    "def collate(records: list[dict]) -> dict[..., list]:\n",
    "    \"\"\"Collate records assuming no fields are missing\"\"\"\n",
    "    out = {}\n",
    "    for record in records:\n",
    "        do_add(record, out)\n",
    "\n",
    "    return {k: np.array(v) for k, v in out.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1239b411",
   "metadata": {},
   "source": [
    "Branchrules and wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491390b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ecole as ec\n",
    "\n",
    "from toybnb.scip.ecole.il.data import Observation\n",
    "\n",
    "from toybnb.scip.ecole.il.brancher import BranchRule, BranchRuleCallable\n",
    "\n",
    "from toybnb.scip.ecole.il.brancher import strongbranch, randombranch\n",
    "from toybnb.scip.ecole.il.brancher import batched_ml_branchrule, ml_branchrule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b700c7c",
   "metadata": {},
   "source": [
    "A branchrule that communicates with a central action server, that attempts to process the requests in batch for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba3fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toybnb.scip.ecole.il.brancher import BranchingServer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a2d86e",
   "metadata": {},
   "source": [
    "A procedure to seed Ecole's PRNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2d48a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ecole import RandomGenerator\n",
    "\n",
    "from functools import partial\n",
    "from toybnb.scip.ecole.il.env import ecole_seed, make_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e79622",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbc5f0f",
   "metadata": {},
   "source": [
    "## The data source proper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03c3d92",
   "metadata": {},
   "source": [
    "A generator of observation-action-reward data collected from the nodes of SCIP's BnB search tree at which a branching decision was made.\n",
    "- SCIP has a nasty habit of intercepting and muffling Keyboard Interrupts. A workaround is to check\n",
    "if the SCIP's model's status indicates termination due to a sigint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37175d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toybnb.scip.ecole.il.rollout import pool_rollout, evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70534898",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd57a29",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de107a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cd9770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a seed sequence with a fixed entropy pool\n",
    "ss = SeedSequence(None)  # use `ss.entropy` for future reproducibility\n",
    "print(f\"{ss.entropy = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe36b8f",
   "metadata": {},
   "source": [
    "Pipe the generator that mixes several the CO problems into the continupus rollout iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7b456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ecole.instance import CombinatorialAuctionGenerator\n",
    "\n",
    "# CAuc(100, 500), CAuc(50, 250)\n",
    "itco = CombinatorialAuctionGenerator(100, 500, rng=ecole_seed(spawn_one(ss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672c5c51",
   "metadata": {},
   "source": [
    "Allow for 100k samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d323ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_project_graph = \"pre\"  # \"post\"\n",
    "\n",
    "p_drop = 0.2\n",
    "n_embed, n_heads, n_blocks = 64, 4, 1\n",
    "b_edges = True\n",
    "b_norm_first = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600d6e2b",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159bd1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toybnb.scip.ecole.il.nn import NeuralVariableSelector\n",
    "\n",
    "mod = NeuralVariableSelector(\n",
    "    19,\n",
    "    5,\n",
    "    n_embed,\n",
    "    n_heads,\n",
    "    n_blocks,\n",
    "    p_drop,\n",
    "    b_norm_first=b_norm_first,\n",
    "    s_project_graph=s_project_graph,\n",
    "    b_edges=b_edges,\n",
    ").to(device)\n",
    "\n",
    "ckpt = torch.load(\"dump/cauc-norm-first.pt\")\n",
    "mod.load_state_dict(ckpt[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332838a8",
   "metadata": {},
   "source": [
    "List all rules we want to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7b37e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the branching server\n",
    "server = BranchingServer(mod, device)\n",
    "server.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b89b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = {\n",
    "    \"trained\": ml_branchrule(mod, device),\n",
    "    \"server\": server.connect,\n",
    "    \"strongbranch\": strongbranch(),\n",
    "    #     \"pseudocostbranch\": strongbranch(True),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b535b73c",
   "metadata": {},
   "source": [
    "Evaluate the branchrules in parallel threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1716087",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "\n",
    "it_co = CombinatorialAuctionGenerator(100, 500)\n",
    "\n",
    "# it = map(lambda a: a[0], zip(it_co, trange(1000, ncols=70)))\n",
    "factories = [partial(make_env, fork) for fork in ss.spawn(12)]\n",
    "it_eval = pool_rollout(it_co, factories, rules, maxsize=24)\n",
    "\n",
    "# collect the evaluation results\n",
    "nfos = {}\n",
    "for item, _ in zip(it_eval, trange(1000, ncols=70)):\n",
    "    do_add(item, nfos)\n",
    "\n",
    "metrics = {k: collate(nfo) for k, nfo in nfos.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8392572",
   "metadata": {},
   "source": [
    "* `n_nodes`, `n_requests`\n",
    "* `n_lpiter`\n",
    "* `f_soltime`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08278268",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
