{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc4a90ea",
   "metadata": {},
   "source": [
    "# Evaluating branchrules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf25b078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fbc898",
   "metadata": {},
   "source": [
    "SeedSequence needs a `.spawn-one` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705f2f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng, SeedSequence\n",
    "\n",
    "\n",
    "def spawn_one(ss: SeedSequence) -> SeedSequence:\n",
    "    return ss.spawn(1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248b39ce",
   "metadata": {},
   "source": [
    "A function to add a dict record to a table (dict-of-lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0e99ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "\n",
    "def do_add(\n",
    "    record: dict, to: dict[..., list], transform: Callable[..., dict] = None\n",
    ") -> dict:\n",
    "    \"\"\"Add the record to a transposed dict of lists.\"\"\"\n",
    "    original = record\n",
    "    if callable(transform):\n",
    "        record = transform(**record)\n",
    "\n",
    "    # assume no fields are missing\n",
    "    for field, value in record.items():\n",
    "        to.setdefault(field, []).append(value)\n",
    "\n",
    "    return original\n",
    "\n",
    "\n",
    "def collate(records: list[dict]) -> dict[..., list]:\n",
    "    \"\"\"Collate records assuming no fields are missing\"\"\"\n",
    "    out = {}\n",
    "    for record in records:\n",
    "        do_add(record, out)\n",
    "\n",
    "    return {k: np.array(v) for k, v in out.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1239b411",
   "metadata": {},
   "source": [
    "Branchrules and wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491390b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ecole as ec\n",
    "\n",
    "from toybnb.scip.ecole.il.data import Observation\n",
    "\n",
    "from toybnb.scip.ecole.il.brancher import BranchRule, BranchRuleCallable\n",
    "\n",
    "from toybnb.scip.ecole.il.brancher import strongbranch, randombranch\n",
    "from toybnb.scip.ecole.il.brancher import batched_ml_branchrule, ml_branchrule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b700c7c",
   "metadata": {},
   "source": [
    "A branchrule that communicates with a central action server, that attempts to process the requests in batch for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba3fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toybnb.scip.ecole.il.threads import BatchProcessor\n",
    "\n",
    "from ecole.core.scip import Stage\n",
    "from ecole.environment import Branching\n",
    "\n",
    "\n",
    "class BranchingServer(BatchProcessor):\n",
    "    \"\"\"Branching variable Server\"\"\"\n",
    "\n",
    "    def connect(self, env: Branching, config: dict = None) -> BranchRuleCallable:\n",
    "        \"\"\"Spawn a new branchrule\"\"\"\n",
    "        co_yield = super().connect()\n",
    "\n",
    "        def _branchrule(obs: Observation) -> int:\n",
    "            if env.model.stage != Stage.Solving:\n",
    "                return None\n",
    "\n",
    "            return int(co_yield(obs))\n",
    "\n",
    "        return _branchrule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a2d86e",
   "metadata": {},
   "source": [
    "A procedure to seed Ecole's PRNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2d48a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ecole import RandomGenerator\n",
    "\n",
    "from toybnb.scip.ecole.il.env import ecole_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e79622",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbc5f0f",
   "metadata": {},
   "source": [
    "## The data source proper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03c3d92",
   "metadata": {},
   "source": [
    "A generator of observation-action-reward data collected from the nodes of SCIP's BnB search tree at which a branching decision was made.\n",
    "- SCIP has a nasty habit of intercepting and muffling Keyboard Interrupts. A workaround is to check\n",
    "if the SCIP's model's status indicates termination due to a sigint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toybnb.scip.ecole.il.rollout import rollout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c3c3b0",
   "metadata": {},
   "source": [
    "The inner logic of the parallel job feeder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e3d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "from queue import Empty, Queue, Full\n",
    "from threading import Event\n",
    "\n",
    "\n",
    "def t_feed(\n",
    "    it: Iterable,\n",
    "    to: Queue,\n",
    "    *,\n",
    "    signal: Event,\n",
    "    err: Queue,\n",
    "    timeout: float = 1.0,\n",
    ") -> None:\n",
    "    \"\"\"Keep putting items from the iterable into the queue, until stopped\"\"\"\n",
    "    try:\n",
    "        item = next(it)\n",
    "        while not signal.is_set():\n",
    "            try:\n",
    "                to.put(item, True, timeout)\n",
    "            except Full:\n",
    "                continue\n",
    "\n",
    "            item = next(it)\n",
    "\n",
    "    except StopIteration:\n",
    "        pass\n",
    "\n",
    "    except BaseException as e:\n",
    "        err.put_nowait(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92602169",
   "metadata": {},
   "source": [
    "The body of a parallel rollout worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2875278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "\n",
    "def t_evaluate(\n",
    "    feed: Queue,\n",
    "    factory: Callable,\n",
    "    branchrules: tuple[BranchRule],\n",
    "    into: Queue,\n",
    "    *,\n",
    "    signal: Event,\n",
    "    err: Queue,\n",
    "    timeout: float = 1.0,\n",
    ") -> None:\n",
    "    \"\"\"Evaluate the `branchrule` on instances from `feed` solved in `factory`,\n",
    "    saving the observations in `into`\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # get the env\n",
    "        env = factory()\n",
    "        while not signal.is_set():\n",
    "            # poll the feed queue for a new job\n",
    "            try:\n",
    "                p = feed.get(True, timeout)\n",
    "            except Empty:\n",
    "                continue\n",
    "\n",
    "            out = {}\n",
    "            # do a rollout on this instance with each branchrule\n",
    "            for name, rule in branchrules.items():\n",
    "                try:\n",
    "                    it = rollout(p, env, rule, {}, stop=signal.is_set)\n",
    "                    while True:\n",
    "                        next(it)\n",
    "\n",
    "                except StopIteration as e:\n",
    "                    # save the final `nfo` data from the branching env,\n",
    "                    #  as it contains the post-search tree stats\n",
    "                    out[name] = e.value\n",
    "\n",
    "            # send the evaluation results of all branchrules\n",
    "            while not signal.is_set():\n",
    "                try:\n",
    "                    into.put(out, True, timeout)\n",
    "                except Full:\n",
    "                    continue\n",
    "\n",
    "                break\n",
    "\n",
    "    except BaseException as e:\n",
    "        err.put_nowait(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3431f5df",
   "metadata": {},
   "source": [
    "The procedure itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a6f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from functools import partial\n",
    "from toybnb.scip.ecole.il.env import make_env\n",
    "\n",
    "\n",
    "def maybe_raise(err: Queue) -> None:\n",
    "    \"\"\"Raise if the error queue has an exception\"\"\"\n",
    "    with err.mutex:\n",
    "        if err.queue:\n",
    "            raise err.queue.popleft()\n",
    "\n",
    "\n",
    "def multievaluate(\n",
    "    feed: Iterable,\n",
    "    ss: SeedSequence,\n",
    "    branchrules: dict[str, BranchRule],\n",
    "    n_jobs: int = 8,\n",
    ") -> Iterable:\n",
    "    ctx = dict(signal=Event(), err=Queue(), timeout=1.0)\n",
    "\n",
    "    # spawn feed thread and the workers\n",
    "    feed_q, rollout_q = Queue(128), Queue(128)\n",
    "    threads = [Thread(target=t_feed, args=(feed, feed_q), kwargs=ctx, daemon=True)]\n",
    "    for fork in ss.spawn(n_jobs):\n",
    "        args = feed_q, partial(make_env, fork), branchrules, rollout_q\n",
    "        threads.append(Thread(target=t_evaluate, args=args, kwargs=ctx, daemon=True))\n",
    "\n",
    "    for t in threads:\n",
    "        t.start()\n",
    "\n",
    "    try:\n",
    "        # the main thread yields results from the rollout output queue\n",
    "        while True:\n",
    "            maybe_raise(ctx[\"err\"])\n",
    "            try:\n",
    "                yield rollout_q.get(True, timeout=5.0)\n",
    "\n",
    "            except Empty:\n",
    "                continue\n",
    "\n",
    "    finally:\n",
    "        ctx[\"signal\"].set()\n",
    "        for t in threads:\n",
    "            t.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70534898",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd57a29",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cd9770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a seed sequence with a fixed entropy pool\n",
    "ss = SeedSequence(None)  # use `ss.entropy` for future reproducibility\n",
    "print(f\"{ss.entropy = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe36b8f",
   "metadata": {},
   "source": [
    "Pipe the generator that mixes several the CO problems into the continupus rollout iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7b456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ecole.instance import CombinatorialAuctionGenerator\n",
    "\n",
    "# CAuc(100, 500), CAuc(50, 250)\n",
    "itco = CombinatorialAuctionGenerator(100, 500, rng=ecole_seed(spawn_one(ss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672c5c51",
   "metadata": {},
   "source": [
    "Allow for 100k samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d323ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_project_graph = \"pre\"  # \"post\"\n",
    "\n",
    "p_drop = 0.2\n",
    "n_embed, n_heads, n_blocks = 32, 1, 1\n",
    "b_edges = True\n",
    "b_norm_first = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600d6e2b",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159bd1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toybnb.scip.ecole.il.nn import NeuralVariableSelector\n",
    "\n",
    "mod = NeuralVariableSelector(\n",
    "    19,\n",
    "    5,\n",
    "    n_embed,\n",
    "    n_heads,\n",
    "    n_blocks,\n",
    "    p_drop,\n",
    "    b_norm_first=b_norm_first,\n",
    "    s_project_graph=s_project_graph,\n",
    "    b_edges=b_edges,\n",
    ")\n",
    "\n",
    "ckpt = torch.load(\"dump/eighth-cauc-pseudocost.pt\")\n",
    "mod.load_state_dict(ckpt[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "02025483",
   "metadata": {},
   "source": [
    "# try the branching server\n",
    "server = BranchingServer(batched_ml_branchrule(mod))\n",
    "server.start()\n",
    "\n",
    "cotest = CombinatorialAuctionGenerator(n_items=50, n_bids=250)\n",
    "env = make_env()\n",
    "nfo = evaluate(next(cotest), env, server.connect, delay=False)\n",
    "\n",
    "server.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332838a8",
   "metadata": {},
   "source": [
    "List all rules we want to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b89b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = {\n",
    "    \"trained\": ml_branchrule(mod),\n",
    "    \"strongbranch\": strongbranch(),\n",
    "    #     \"pseudocostbranch\": strongbranch(True),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b535b73c",
   "metadata": {},
   "source": [
    "Evaluate the branchrules in parallel threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1716087",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "it_co = CombinatorialAuctionGenerator(100, 500)\n",
    "\n",
    "# it = map(lambda a: a[0], zip(it_co, trange(1000, ncols=70)))\n",
    "it_eval = multievaluate(it_co, ss, rules, n_jobs=4)\n",
    "\n",
    "# collect the evaluation results\n",
    "nfos = {}\n",
    "for item, _ in zip(it_eval, trange(1000, ncols=70)):\n",
    "    do_add(item, nfos)\n",
    "\n",
    "metrics = {k: collate(nfo) for k, nfo in nfos.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8392572",
   "metadata": {},
   "source": [
    "* `n_nodes`, `n_requests`\n",
    "* `n_lpiter`\n",
    "* `f_soltime`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08278268",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
