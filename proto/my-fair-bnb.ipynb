{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffc4417e",
   "metadata": {},
   "source": [
    "# Shorter Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df50b230",
   "metadata": {},
   "source": [
    "Branch-and-bound method is a general algorithm to solve optimization problems, which allow access to a sub-optimality oracle -- a procedure, which, given an instance of a problem $\n",
    "    \\min\\{f(x) \\colon x \\in X\\}\n",
    "$, returns a non-trivial lower bound $\\tau$ such that $\\tau \\leq f(x)$ for all $x \\in X$. BnB cuts-off subsets of the feasibility set $X$ in a methodical and structured manner, but still has to make sure no region is missed.\n",
    "- In fact, bnb can be adapted to the case, when the problem allows access only to a SAT oracle, which, given $(f, X, \\tau)$, decides whether $\\exists x \\in X$ such that $f(x) \\leq \\tau$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af0d8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy import sparse as sp\n",
    "\n",
    "from numpy import ndarray\n",
    "from numpy.random import default_rng\n",
    "\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from time import monotonic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24761538",
   "metadata": {},
   "source": [
    "Invert our bnb solver at the branch variable selection, while still using the depth-first node selector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d9010a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toybnb import search as bnb\n",
    "from toybnb.milp import MILP\n",
    "from toybnb.coro import Coroutine\n",
    "from typing import Generator\n",
    "\n",
    "\n",
    "def inverted_search(p: MILP, nodesel: callable = bnb.nodesel_dfs) -> ...:\n",
    "    \"\"\"Inverted variable branching as generator\"\"\"\n",
    "\n",
    "    # need access to `co` through closure\n",
    "    def branchrule(T: nx.DiGraph, node: int) -> int:\n",
    "        return co.co_yield((T, node))\n",
    "\n",
    "    # def nodesel(G: nx.DiGraph, *reschedule: int) -> int:\n",
    "    #     # yields must use a tag for use in a state machine\n",
    "    #     return co.co_yield((\"nodesel\", G, *reschedule))\n",
    "\n",
    "    args = p, nodesel, branchrule\n",
    "    co = Coroutine(bnb.search, args=args, kwargs={})\n",
    "    return iter(co)\n",
    "\n",
    "\n",
    "def branching(p: MILP, nodesel: callable = bnb.nodesel_dfs) -> tuple[nx.DiGraph, int]:\n",
    "    \"\"\"Branching that allows each node to be visited only once\"\"\"\n",
    "    it, visited, var = inverted_search(p, nodesel), set(), None\n",
    "    try:\n",
    "        while True:\n",
    "            T, node = it.send(var)\n",
    "            while node in visited:\n",
    "                T, node = it.throw(IndexError)\n",
    "\n",
    "            visited.add(node)\n",
    "            var = yield T, node\n",
    "            # assert it.gi_frame.f_locals[\"self\"].co_is_suspended\n",
    "\n",
    "    except StopIteration as e:\n",
    "        return e.value, None\n",
    "\n",
    "\n",
    "def send(it: Generator, value: ...) -> ...:\n",
    "    \"\"\"Send a value to the generator and get a value from it in return\"\"\"\n",
    "    try:\n",
    "        return it.send(value), False\n",
    "\n",
    "    except StopIteration as e:\n",
    "        return e.value, True\n",
    "\n",
    "\n",
    "class GeneratorEnv:\n",
    "    \"\"\"A wrapper to make generators into envs.\"\"\"\n",
    "\n",
    "    def reset(self, it: Generator) -> ...:\n",
    "        self.it = iter(it)\n",
    "        return send(self.it, None)\n",
    "\n",
    "    def step(self, act: ...) -> ...:\n",
    "        return send(self.it, act)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942b53fd",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4405ffdb",
   "metadata": {},
   "source": [
    "#### A generic random MILP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227f7625",
   "metadata": {},
   "source": [
    "A Mixed Integer Linear Programs (MILP) is a linear program with integrality constraints. A MILP has the following generic form:\n",
    "\n",
    "$$\n",
    "\\min\\Bigl\\{\n",
    "    c^\\top x\n",
    "    \\colon\n",
    "    A x \\leq b\n",
    "    \\,, x \\in \\bigl[l, u\\bigr]\n",
    "    \\,,\n",
    "    x \\in \\mathbb{Z}^m \\times \\mathbb{R}^{n-m}\n",
    "\\Bigr\\}\n",
    "    \\,, $$\n",
    "\n",
    "where $A \\in \\mathbb{R}^{r \\times n}$, $b \\in \\mathbb{R}^r$, $\n",
    "    l, u \\in \\mathbb{R}^n\n",
    "$ with $l \\leq u$ and $1 \\leq m \\leq n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad62824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toybnb.milp import generate as generate_generic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f584709",
   "metadata": {},
   "source": [
    "#### A generator for MIS problems\n",
    "\n",
    "For a undirected graph $G = (V, E)$ the Maximum independent set problem is\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    & \\underset{x\\in \\{0, 1\\}}{\\text{maximize}}\n",
    "      & & \\sum_{v \\in G} x_v\n",
    "          \\\\\n",
    "    & \\text{subject to}\n",
    "      & & \\forall uv \\in E\n",
    "          \\colon x_u + x_v \\leq 1\n",
    "          \\,.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The generator implemented in toybnb.milp uses the Barabasi-Albert graph generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1284ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toybnb.milp import generate_mis_ba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648c2a10",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4024e5e",
   "metadata": {},
   "source": [
    "### ToyBNB tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604ee7c2",
   "metadata": {},
   "source": [
    "Generate a simple problem and solve it with SCIP to get the reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c20a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it = generate_generic(100, 50, 10, seed=1458)\n",
    "# it = generate_generic(150, 50, 15, seed=1458)\n",
    "it = generate_generic(50, 50, 10, seed=1458)  # many infeasible nodes\n",
    "# it = generate_mis_ba(210, seed=454)\n",
    "\n",
    "# it = generate_generic(1500, 1200, 5, seed=53912)\n",
    "# it = generate_generic(50, 38, 10, seed=1458)  # very slow ub decay\n",
    "\n",
    "# it = generate_mis_ba(500, seed=69420)\n",
    "p = next(it)  # x = it.gi_frame.f_locals[\"p\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f9d0d8",
   "metadata": {},
   "source": [
    "BnB for MILP is an exhaustive search which employs _a continuous relaxation of the MILP_ as the oracle in order to eliminate sub-regions of the feasibility set.\n",
    "Let the integer feasibility set and its continuous relaxation be, respectively,\n",
    "$$\n",
    "\\begin{align}\n",
    "S\n",
    "    &= \\bigl\\{\n",
    "        x \\in {\\color{red}{\\mathbb{Z}^m}} \\times \\mathbb{R}^{n-m}\n",
    "        \\colon A x \\leq b\n",
    "        \\,, x \\in [l, u] \n",
    "    \\bigr\\}\n",
    "    \\,, \\\\\n",
    "\\breve{S}\n",
    "    &= \\bigl\\{\n",
    "        x \\in {\\color{blue}{\\mathbb{R}^m}} \\times \\mathbb{R}^{n-m}\n",
    "        \\colon A x \\leq b\n",
    "        \\,, x \\in [l, u] \n",
    "    \\bigr\\}\n",
    "    \\,.\n",
    "\\end{align}\n",
    "$$\n",
    "The linear problem\n",
    "$$\n",
    "\\breve{f}\n",
    "    = \\min_x \\{\n",
    "        c^\\top x\n",
    "        \\colon x \\in \\breve{S}\n",
    "    \\}\n",
    "    \\,, $$\n",
    "offers a _lower bound on the achievable value_ of the objective in $S$, i.e. every integer-feasible $x \\in S$ necessarily has $\n",
    "    \\breve{f} \\leq c^\\top x\n",
    "$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba50cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toybnb.tree import subproblem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a2930a",
   "metadata": {},
   "source": [
    "Solve the MILP, generated above, with random variable branching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26c259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "with tqdm(ncols=70) as pb:\n",
    "    rng = default_rng(671)\n",
    "    env = GeneratorEnv()\n",
    "    (T, node), fin = env.reset(branching(p))\n",
    "    while not fin:\n",
    "        times.append(monotonic())\n",
    "        pb.update(1)\n",
    "\n",
    "        # pick a random index\n",
    "        _, _, mask = subproblem(T, node)\n",
    "        var = rng.choice(np.flatnonzero(mask))\n",
    "\n",
    "        # branch\n",
    "        (T, node), fin = env.step(var)\n",
    "    times.append(monotonic())\n",
    "\n",
    "assert node is None\n",
    "times_rng = np.array(times) - times[0]\n",
    "nn_rng, pv_rng, dv_rng, lb_rng = map(np.array, zip(*T.graph[\"track\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab2c889",
   "metadata": {},
   "source": [
    "Plot the primal and dual bound history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb2fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 2), dpi=300)\n",
    "\n",
    "ax.plot(dv_rng)\n",
    "ax.plot(pv_rng)\n",
    "ax.plot(lb_rng)\n",
    "\n",
    "ax.twinx().plot(times_rng[1:], c=\"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d167970",
   "metadata": {},
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60911105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toybnb.tree import Status\n",
    "\n",
    "# we have incumbent >= lp ins `dual` and either closed\n",
    "#  or integer-feasible\n",
    "st = nx.get_node_attributes(T, \"status\")\n",
    "assert all(st[n] in (Status.FEASIBLE, Status.CLOSED) for _, n in T.graph[\"duals\"])\n",
    "\n",
    "is_leaf = {n: not bool(T[n]) for n in T}\n",
    "is_fathomed = {n: s != Status.OPEN for n, s in st.items()}\n",
    "assert all(is_fathomed.values())\n",
    "\n",
    "assert T.nodes[T.graph[\"root\"]][\"best\"] is T.graph[\"incumbent\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7a7465",
   "metadata": {},
   "source": [
    "A random branching strategy is absolutely oblivious to the nature and geometry of the underlying problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac295d0b",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f81b5c5",
   "metadata": {},
   "source": [
    "### lower-bound aware depth-first node selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0cc9cb",
   "metadata": {},
   "source": [
    "A node selection strategy is as important as the variable selection heuristic: the latter's goal is to achieve subset cutoff as soon as possible, while the fomer's is to dive into the nodes with the loosest lower bound possible so as to eat up the potential primal-dual margin in a sub-tree as fast as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09e359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toybnb.tree import Status\n",
    "\n",
    "\n",
    "def nodesel_dfs_lb(G: nx.DiGraph, *reschedule: int) -> int:\n",
    "    \"\"\"Prioritize the child with the worst lp lower bound.\"\"\"\n",
    "    stack, dt = G.graph[\"queue\"], G.nodes\n",
    "\n",
    "    def lower_bound(n: int) -> float:\n",
    "        return dt[n][\"lp\"].fun\n",
    "\n",
    "    # prioritize the children by their lp lower bound, but\n",
    "    #  schedule only OPEN nodes. The less tight the lower\n",
    "    #  bound, intuitively, the more margin there is for an\n",
    "    #  integer feasible solution.\n",
    "    for n in sorted(reschedule, key=lower_bound, reverse=True):\n",
    "        if dt[n][\"status\"] == Status.OPEN:\n",
    "            stack.append(n)\n",
    "\n",
    "    while stack:\n",
    "        n = stack.pop()\n",
    "        if dt[n][\"status\"] == Status.OPEN:\n",
    "            return n\n",
    "\n",
    "    raise IndexError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c98cf40",
   "metadata": {},
   "source": [
    "Run random branching with a slightly smarter nodesel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d3ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "with tqdm(ncols=70) as pb:\n",
    "    rng = default_rng(671)\n",
    "    env = GeneratorEnv()\n",
    "    (T, node), fin = env.reset(branching(p, nodesel_dfs_lb))\n",
    "    while not fin:\n",
    "        times.append(monotonic())\n",
    "        pb.update(1)\n",
    "\n",
    "        # pick a random index\n",
    "        _, _, mask = subproblem(T, node)\n",
    "        var = rng.choice(np.flatnonzero(mask))\n",
    "\n",
    "        # branch\n",
    "        (T, node), fin = env.step(var)\n",
    "    times.append(monotonic())\n",
    "\n",
    "assert node is None\n",
    "times_rng_dfs = np.array(times) - times[0]\n",
    "nn_rng_dfs, pv_rng_dfs, dv_rng_dfs, lb_rng_dfs = map(np.array, zip(*T.graph[\"track\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89881f33",
   "metadata": {},
   "source": [
    "The trace and the value function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c255bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 2), dpi=300)\n",
    "\n",
    "ax.plot(dv_rng_dfs)\n",
    "ax.plot(pv_rng_dfs)\n",
    "ax.plot(lb_rng_dfs)\n",
    "\n",
    "ax.twinx().plot(times_rng_dfs[1:], c=\"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053f87a7",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aad781",
   "metadata": {},
   "source": [
    "### Strong branching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601f829c",
   "metadata": {},
   "source": [
    "Strong branching selects a variable to split the MILP with based on exhaustive look-ahead for the most promising  lower bound (lp relaxation, dual bound), with the goal to cut off a half of the search space as quickly as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da023a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper for scipy's LP solver for the relaxed problem w/o integrality\n",
    "from toybnb.tree import lpsolve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8164aa6",
   "metadata": {},
   "source": [
    "Suppose, we happen to have a candidate (incumbent) $x_*$ with $f^* = c^\\top x_*$, which is integer-feasible in the __original problem's domain__ of which $S$ is a proper subset, but with $x_* \\notin S$.\n",
    "Then $f^* < \\breve{f}$ __certifies__ that there is __no integer-feasible__ $x$ in $\n",
    "    \\breve{S} \\supseteq S\n",
    "$ with a lower objective value than $x_*$. This means that $\\breve{S}$, including the entirety of $S$, may be excluded from the search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75968768",
   "metadata": {},
   "source": [
    "The lp-gains $\\Delta_\\pm$ are computed based on the left and right relaxation of the integer problem.\n",
    "\n",
    "If $\\breve{f} \\leq f^*$ and $\\breve{x} \\notin S$, there is some $j=1..m$ such that $\\breve{x}^j \\notin \\mathbb{Z}$. Since it would be impossible for any integer-feasible solution $x \\in S$ to have $\n",
    "    x^j \\in \\bigl(\n",
    "        \\lfloor \\breve{x}^j \\rfloor,\n",
    "        \\lceil \\breve{x}^j \\rceil\n",
    "    \\bigr)\n",
    "$, it becomes reasonable to split the original feasibility set $S$ in two non-overlapping subsets:\n",
    "$$\n",
    "    \\underbrace{\n",
    "        \\bigl\\{\n",
    "            x \\in \\mathbb{R}^n \\colon\n",
    "            x^j \\leq \\lfloor \\breve{x}^j \\rfloor\n",
    "        \\bigr\\}  % \\times \\mathbb{R}^{n-1}\n",
    "    }_{R^j_-}\n",
    "    \\uplus\n",
    "    \\underbrace{\n",
    "        \\bigl\\{\n",
    "            x \\in \\mathbb{R}^n \\colon\n",
    "            \\lceil \\breve{x}^j \\rceil \\leq x^j\n",
    "        \\bigr\\}  % \\times \\mathbb{R}^{n-1}\n",
    "    }_{R^j_+}\n",
    "    \\,.\n",
    "$$\n",
    "Note that it is sufficient to split the region $S$ with respect to one variable only, since every other split is guaranteed by integer-feasiblity __not__ to contain a feasible solution in the excluded region of the $j$-th variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45f8548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the feasibility set on a given variable with the specified threshold\n",
    "from toybnb.tree import split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a595f",
   "metadata": {},
   "source": [
    "The sub-regions $\n",
    "    S^j_\\pm = S \\cap R^j_\\pm\n",
    "$ bring about new lower bounds $\n",
    "\\breve{f}^j_\\pm\n",
    "    = \\min_x \\{\n",
    "        c^\\top x\\colon x \\in \\breve{S}^j_\\pm\n",
    "    \\}\n",
    "$. The new sub-problems are obtained from the original by modifying the bounds of the $j$-th variable: $\n",
    "    \\bigl[l^j, \\lfloor \\breve{x}^j \\rfloor\\bigr]\n",
    "$ and $\n",
    "    \\bigl[\\lceil \\breve{x}^j \\rceil, u^j\\bigr]\n",
    "$. The amount of the objective value, by which each bound is tightened, is the _gain_:\n",
    "$$\n",
    "\\Delta^j_\\pm\n",
    "    = \\breve{f}^j_\\pm - \\breve{f}\n",
    "    \\geq 0\n",
    "    \\,. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4c073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute LP branching gains for each candidate in the binary mask\n",
    "from toybnb.tree import lp_gains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cac451",
   "metadata": {},
   "source": [
    "Scoring functions\n",
    "* additive $\n",
    "    s_j = \\mu \\max\\{\\Delta^j_-, \\Delta^j_+\\}\n",
    "        + (1 - \\mu) \\min\\{\\Delta^j_-, \\Delta^j_+\\}\n",
    "$\n",
    "* multiplicative $\n",
    "    s_j = \\Delta^j_- \\Delta^j_+\n",
    "$ -- the default scorefunc in SCIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533e984d",
   "metadata": {},
   "source": [
    "The strong branching rule enumerates all fractional variables and evaluates the lp lower bound changes on a split with respect to each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a99f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Choose a variable to split the problem with, based on exhaustive look-ahead.\"\"\"\n",
    "\n",
    "times = []\n",
    "with tqdm(ncols=70) as pb:\n",
    "    n_lpit = 0\n",
    "    env = GeneratorEnv()\n",
    "    (T, node), fin = env.reset(branching(p, nodesel_dfs_lb))\n",
    "    while not fin:\n",
    "        times.append(monotonic())\n",
    "        pb.update(1)\n",
    "\n",
    "        # get the up-lo branching gains\n",
    "        p_, lp_, mask = subproblem(T, node)\n",
    "        gains, nit = lp_gains(p_, lp_, mask)\n",
    "        n_lpit += nit\n",
    "\n",
    "        # scores = mu * gains.max(-1) + (1 - mu) * gains.min(-1)\n",
    "        scores = gains[:, 0] * gains[:, 1]\n",
    "\n",
    "        # branch\n",
    "        var = np.nanargmax(scores)\n",
    "        (T, node), fin = env.step(var)\n",
    "    times.append(monotonic())\n",
    "\n",
    "assert node is None\n",
    "times_sb = np.array(times) - times[0]\n",
    "nn_sb, pv_sb, dv_sb, lb_sb = map(np.array, zip(*T.graph[\"track\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b494c418",
   "metadata": {},
   "source": [
    "Plot the track, the value paths, and the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41be3077",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 2), dpi=300)\n",
    "\n",
    "ax.plot(dv_sb)\n",
    "ax.plot(pv_sb)\n",
    "ax.plot(lb_sb)\n",
    "\n",
    "ax.twinx().plot(times_sb[1:], c=\"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64db179c",
   "metadata": {},
   "source": [
    "Strong branching is [provably](#citation_needed) the best branching rule in terms of search tree efficiency (the overall number of nodes). However, the exhaustive enumeration of all candidates coupled with invoking an expensive lp solver twice for each, makes the SB rule very computationally expensive in practice.\n",
    "* At the same time time [there are](https://arxiv.org/abs/2110.10754.pdf) MILP, which produce lp relaxations that fail to represent problem progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf1a070",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5113e7",
   "metadata": {},
   "source": [
    "### Pseudocost branching\n",
    "\n",
    "Whenever a fractional variable $j$ is picked for branching and both sub-porblems have feasible lp relaxations, we can compute its, so called, _branching pseudocosts_: $\n",
    "    p^j_\\pm = \\frac{\\Delta^j_\\pm}{\\phi^j_\\pm}\n",
    "$ where $\n",
    "    \\phi^j_- = \\breve{x}^j - \\lfloor \\breve{x}^j \\rfloor\n",
    "$, and $\n",
    "    \\phi^j_+ = \\lceil \\breve{x}^j \\rceil - \\breve{x}^j\n",
    "$. Conceptually, the $p^j_\\pm$ measure the rate of degradation of the objective function value between the nested lp relaxations caused by splitting on a given variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679fbbf2",
   "metadata": {},
   "source": [
    "Using the envelope theorem, it is possible to view the pseudocosts as crude finite-difference approximations to sensitivity of the function to changing the bound constraint at the current solution: $\n",
    "    p^j_\\pm\n",
    "        \\approx \\partial_{\\theta_j} \\breve{f}_\\theta\n",
    "$.\n",
    "\n",
    "- the envelope theorem for the problem $\n",
    "    f(\\theta) = \\min_x \\{f(x, \\theta) \\colon g_k(x, \\theta) \\geq 0\\}\n",
    "$ states that, if in some neighbourhood of the $\\theta$ the solution $\n",
    "    x^*(\\theta)\n",
    "$ is differentiable, then the value function $\n",
    "    f^*(\\theta) = f(x^*(\\theta), \\theta)\n",
    "$ is differentiable with\n",
    "$$\n",
    "\\partial_\\theta f^*(\\theta)\n",
    "    = \\partial_2 f(x^*(\\theta), \\theta) - \\sum_k \\lambda^*_k(\\theta) \\partial_2 g_k(x^*(\\theta), \\theta)\n",
    "    \\,. $$\n",
    "    - if a constraint is non-binding at $x_*(\\theta)$, then it is non-binding in some open neighbourhood, and thus infinitesimal changes to it do not affect the solution and value\n",
    "    - if $g_k(x, \\theta) = h_k(x, \\theta_1) - \\theta_2$ for some $k$ and all other constraints do not depend on $\\theta_2$, then $\n",
    "        \\partial_{\\theta_2} f^*(\\theta)\n",
    "            = \\lambda^*_k(\\theta)\n",
    "    $.\n",
    "    - p.5 of [these notes](http://www.u.arizona.edu/~mwalker/MathCamp2021/EnvelopeTheorem.pdf) seems like a good introductory reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848dd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Acc = namedtuple(\"Acc\", \"n,v\")\n",
    "\n",
    "\n",
    "def fractionality(x: ndarray) -> ndarray:\n",
    "    \"\"\"Compute the fractionality of each variable\"\"\"\n",
    "    return np.stack((x - np.floor(x), np.ceil(x) - x), axis=-1)\n",
    "\n",
    "\n",
    "def acc_get_estimate(acc: Acc, *, min: float = 1e-4, epsilon: float = 1e-5) -> ndarray:\n",
    "    # compute the Laplace-corrected average estimate\n",
    "    n = acc.n.sum(0, keepdims=True)\n",
    "    coef = n / (n + len(acc.n) * epsilon)\n",
    "    size = (acc.n + epsilon) * coef\n",
    "\n",
    "    return np.clip(acc.v / size, min, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2958047",
   "metadata": {},
   "source": [
    "If the split results in an infeasible sub-problem, researchers suggest to use a [_fake objective value_](http://www.or.deis.unibo.it/andrea/pscost-ISMP2009.pdf), computed based on the parent's lp value and the averaged pseudocost of all other variables multiplied by $\\phi^j_\\pm$:\n",
    "$$\n",
    "\\tilde{p}^j_\\pm\n",
    "    = \\frac{\n",
    "        \\overbrace{\n",
    "            \\breve{f} + A \\bigl( \\bar{p}_\\pm \\phi^j_\\pm + \\epsilon \\bigr)\n",
    "        }^{\\text{fake objective value}}\n",
    "        - \\breve{f}\n",
    "    }{\\phi^j_\\pm}\n",
    "    \\,, $$\n",
    "for a small $\\epsilon > 0$, a large $A > 0$, and $\\bar{p}_\\pm$ -- the average pseudocost across the integer variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637ad25c",
   "metadata": {},
   "source": [
    "Whenever a pseudocost for a fractional variable is not available, we use partial strong branching to seed the initial up-lo gain estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5f0dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import isfinite\n",
    "\n",
    "\n",
    "def update_pseudocosts(pc: Acc, T: nx.DiGraph, node: int) -> None:\n",
    "    p = T.nodes[node][\"p\"]\n",
    "\n",
    "    # compute pseudocosts\n",
    "    for c, dt in T[node].items():\n",
    "        # decide which pseudocost to update\n",
    "        k = 0 if dt[\"key\"] < 0 else 1\n",
    "        j, g, f = dt[\"j\"], dt[\"g\"], dt[\"f\"]\n",
    "\n",
    "        # compute pseudocosts and handle infeasible lp gains\n",
    "        pcost = g / f\n",
    "        if not isfinite(pcost):\n",
    "            # on the one hand, we want the pcosts to reflect the dual\n",
    "            #  gain from splitting by a variable, and at the same time\n",
    "            #  cut off a sub-problem as quickly as possible. On the\n",
    "            #  other hand, spoiling the pcosts now with a really HIGH\n",
    "            #  gain, is bad for the using pcost estimate at other nodes.\n",
    "            continue\n",
    "\n",
    "            # fake = lp.fun + (avg_pcost * f + eps) * LARGE\n",
    "            pc_avg = pc.v[: p.m].sum(0) / pc.n[: p.m].sum(0)\n",
    "\n",
    "            # pcost = (fake - lp.fun) / f\n",
    "            pcost = (float(pc_avg[k]) * f + 1e-2) * 1e4 / f\n",
    "\n",
    "        # bump the branching counter and update averages in-place\n",
    "        pc.n[j, k] += 1\n",
    "        pc.v[j, k] += pcost\n",
    "        # pc.v[j, k] += (pcost - pc.v[j, k]) / pc.n[j, k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbce3ed",
   "metadata": {},
   "source": [
    "Let's try the pseudocost branching approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6368ddd0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "node, times = None, []\n",
    "with tqdm(ncols=70) as pb:\n",
    "    n_lpit = 0\n",
    "    env = GeneratorEnv()\n",
    "\n",
    "    last = node\n",
    "    (T, node), fin = env.reset(branching(p, nodesel_dfs_lb))\n",
    "\n",
    "    # get the up-lo pseudocosts\n",
    "    n = T.graph[\"p\"].n\n",
    "    pc = Acc(np.zeros((n, 2)), np.zeros((n, 2)))\n",
    "    while not fin:\n",
    "        times.append(monotonic())\n",
    "\n",
    "        pb.update(1)\n",
    "        assert not np.isnan(pc.v).any()\n",
    "\n",
    "        # get the up-lo branching gains\n",
    "        p_, lp_, mask = subproblem(T, node)\n",
    "        cands = np.flatnonzero(mask)\n",
    "        assert len(cands) > 0\n",
    "\n",
    "        frac = fractionality(lp_.x)\n",
    "\n",
    "        # pick which pseudocosts need to be initialized\n",
    "        mask = ((pc.n == 0.0).any(-1)) & (mask > 0)\n",
    "        # pb.set_postfix_str(f\"{mask.sum()} {bnb.bnb.gap(T):.2%}\")  # XXX slow\n",
    "        if mask.any():\n",
    "            gains, nit = lp_gains(p_, lp_, mask)\n",
    "            n_lpit += nit\n",
    "\n",
    "            # get the pseudocosts (costs as in `c_j`)\n",
    "            pcost = np.clip(gains / frac, 0, abs(p_.c).max())\n",
    "            pc.v[mask] = pcost[mask]\n",
    "            pc.n[mask] = 10  # XXX we can tweak this parameter\n",
    "\n",
    "        # decide, which variable to branch on\n",
    "        gains = acc_get_estimate(pc, min=1e-5) * frac\n",
    "        # scores = mu * gains.max(-1) + (1 - mu) * gains.min(-1)\n",
    "        scores = gains[:, 0] * gains[:, 1]\n",
    "        var = cands[scores[cands].argmax()]\n",
    "\n",
    "        # branch\n",
    "        last = node\n",
    "        (T, node), fin = env.step(var)\n",
    "        update_pseudocosts(pc, T, last)\n",
    "\n",
    "    times.append(monotonic())\n",
    "\n",
    "assert node is None\n",
    "times_pc = np.array(times) - times[0]\n",
    "nn_pc, pv_pc, dv_pc, lb_pc = map(np.array, zip(*T.graph[\"track\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18596d9",
   "metadata": {},
   "source": [
    "Plot the primal-dual bounds evolution, the value function paths, and the search tree for pseudocost branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff261b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 2), dpi=300)\n",
    "\n",
    "ax.plot(dv_pc)\n",
    "ax.plot(pv_pc)\n",
    "ax.plot(lb_pc)\n",
    "\n",
    "ax.twinx().plot(times_pc[1:], c=\"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90b9036",
   "metadata": {},
   "source": [
    "Plot the final pseudocost estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7fc4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 2), dpi=300)\n",
    "\n",
    "lo, up = acc_get_estimate(pc).T\n",
    "ax.plot(up / up.max(), label=\"up\")\n",
    "ax.plot(-lo / lo.max(), label=\"lo\")\n",
    "ax.legend(fontsize=\"xx-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecab02af",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9640929",
   "metadata": {},
   "source": [
    "How fast does each method decrease the primal bound?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2465c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 2), dpi=300)\n",
    "\n",
    "(l,) = ax.semilogx(pv_rng, label=\"rng\", alpha=0.75)\n",
    "# ax.semilogx(lb_rng, c=l.get_color(), alpha=0.75)\n",
    "\n",
    "(l,) = ax.semilogx(pv_rng_dfs, label=\"rng-dfs\", alpha=0.75)\n",
    "# ax.semilogx(lb_rng_dfs, c=l.get_color(), alpha=0.75)\n",
    "\n",
    "(l,) = ax.semilogx(pv_sb, label=\"sb\", alpha=0.75)\n",
    "# ax.semilogx(lb_sb, c=l.get_color(), alpha=0.75)\n",
    "\n",
    "(l,) = ax.semilogx(pv_pc, label=\"pc\", alpha=0.75)\n",
    "# ax.semilogx(lb_pc, c=l.get_color(), alpha=0.75)\n",
    "\n",
    "ax.legend(fontsize=\"xx-small\", ncol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e8dd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 2), dpi=300)\n",
    "\n",
    "ax.plot(times_rng, label=\"rng\", alpha=0.75)\n",
    "ax.plot(times_rng_dfs, label=\"rng-dfs\", alpha=0.75)\n",
    "ax.plot(times_sb, label=\"sb\", alpha=0.75)\n",
    "ax.plot(times_pc, label=\"pc\", alpha=0.75)\n",
    "\n",
    "ax.legend(fontsize=\"xx-small\", ncol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8925f388",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a7ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d930f1",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fce825f",
   "metadata": {},
   "source": [
    "# Log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353f67f0",
   "metadata": {},
   "source": [
    "Reinventing the bicycle gives one better understanding of its inner workings and design.\n",
    "So in this notebook I re-implement a BnB algorithm for Mixed Integer Linear Programs.\n",
    "\n",
    "The following log is related to an earlier version and development of the toy bnb algorithm around the 8th of October, 2022.\n",
    "\n",
    "When doing this study i proceeded through the following steps:\n",
    "1. i started with defining a MILP specification format, that compatible with scipy's `linprog` API\n",
    "  * initially i used list of tuples format for lower/upper bounds, but then, after digging through the code of `scipy.optimize` i discovered that passing $n \\times 2$ numpy arrays with $\\pm\\infty$ works just fine (and is preferable, actually).\n",
    "\n",
    "2. then i implemented the key feasibility checkers\n",
    "  * bounding box $x_j \\in \\bigl[l_j, u_j\\bigr]$\n",
    "  * upper bound linear inequality constraints $A_\\mathrm{ub} x \\leq b_\\mathrm{ub}$\n",
    "  * linear equality constraints $A_\\mathrm{eq} x = b_\\mathrm{eq}$\n",
    "  * integer feasibility $x \\in \\mathbb{Z}^m \\times \\mathbb{R}^{n-m}$\n",
    "\n",
    "3. the `lpsolve` procedure, at first, dealt with list-of-tuples bounds, but was later reduced to an interface function\n",
    "\n",
    "4. then `new` and `add` functions were added. Initially, the lp relaxation was computed outside of `add`, but it was reasonable to put the step inside\n",
    "\n",
    "5. then i implemented the `bnb_begin` function (used to call `lpsolve`, before moving into `add`) and sketched the main loop of the bnb search: pruning by lower bound, picking the next node to process, and splitting (no infeasibility/integer feasibility fathoming yet). There i immediately started using the min-heap for pruning certifiably sub-optimal sub-problems.\n",
    "\n",
    "6. with adding incumbent tracking, wild random branching, and variable splitting blocks the loop's body grew ever larger. So i factored three procedures out of it: `bnb_prune`, `bnb_update_incumbent`, and `bnb_branch`.\n",
    "  - atm, we use a single global incumbent, but likely that the MILP has many solutions\n",
    "    - [ ] implement storage for the case when there is solution multiplicity (18th of November, 2022)\n",
    "  - [x] it would be structurally nice to make the stats more `recursive`, and let each node have its own set of incumbents that are best-so-far in that node's sub-problem.\n",
    "\n",
    "7. variable picking logic was then also moved outside of the branching routine\n",
    "\n",
    "8. i tinkered with a method to conveniently store branching rules' data and implemented node-local dunder attributes, that allowed the rules to be stateful\n",
    "  - [ ] add a mask that indicates which variables were branched on, so that if we ever want to mix up branching rules on the fly, that they can communicate each other's choices\n",
    "\n",
    "9. initially my bnb implementation __did not re-introduce__ not yet fully processed nodes into the dual bound max-heap, which resulted in sub-optimal solutions, since __not all branching alternatives were explored__.\n",
    "  - [x] currently the dual bound max-heap also serves as the sub-problem prioritizer. This has to change.\n",
    "  - this is the reason i decided to study bnb by _reinventing_ it: it was not clear to me, based on my tinkering with `ecole` and tree search retrieval by RETRO, how SCIP explored branching alternatives, if at all. Also i had a misconception about what gap it uses to gauge optimization progress.\n",
    "\n",
    "10. after many attempts to track the status of each node (global fathomed/pruned sets, local flags) it finally dawned on me to introduce common node status codes, that allowed finer tracking of fathomed nodes:\n",
    "  - __INFEASIBLE__: lp relaxation is infeasible, hence so the node's sub-problem is also infeasible\n",
    "  - __INTEGER FEASIBLE__: the relaxation produced a solution that satisfies the integrality constraints, hence a global optimum for the node's MILP sub-problem was found, and there is no need to process it further\n",
    "  - __PRUNED__: the lp produced a lower bound on all possible solutions to this node's MILP, that is higher than some integer feasible solution founds elsewhere. Thus we have a theoretical guarantee that it cannot contain a solution to the original root MILP.\n",
    "  - __CLOSED__ and __OPEN__: fully processed nodes or nodes that still have some un-branched fractional variables, respectively.\n",
    "  - status code greatly helped with debugging the search and understanding if it was operating correctly\n",
    "\n",
    "11. I added gap tracking, `bnb_scip_gap` as defined by SCIP, to monitor progress, and finally put together the `bnb_search` procedure from the bare loop, that was running in a cell\n",
    "\n",
    "12. (around 15th of October) Having become content with the slow but steady operation on the toy problems, i decided to apply this code on the crab allocation problem. This attempt failed miserably, since the algorithm worked way to slow. Even with the problem $56$ times smaller, the speed was still a huge issue. And the `linprog` solver was very unhappy with the allocation problem, complaining about its ill-posedness.\n",
    "  - Also strong branching preformed much worse than random branching, for some reason. I suspect the issue is with incorrect node prioritization (indeed it was in hindsight)\n",
    "\n",
    "13. I started experimenting with `presolve` in `scipy.optimize` sub-package, the code which i studied for hints at ways to improve the runtime. Serendipitously, i stumbled on the HiGHS linear solver, which tremendously sped up the procedure. Now at least the crab problem's gap started decreasing!\n",
    "\n",
    "14. I suspected that backtracking to a still open node and branching on another variable and then diving could potentially produce a sub-problem the lp feasibility of which is covered by the feasibility region of some other __already__ solved problem. I confirmed by suspicions by inspecting the bounding boxes of the sub-problems produced by the bnb.\n",
    "  - [ ] ~~we need to implement a lookup for solved sub-MILP that matches by covering bounding boxes (see `bnb_find_solved` stub and `bnb_update_interval_trees`)~~\n",
    "  - (18th of November, 2022) the problem of feasibility subset revisits was due to branching more than once from every open node (see below, and the newer description above)\n",
    "\n",
    "15. Started taking node scheduling responsibility off the dual bound max-heap\n",
    "  - [x] `bnb_schedule_node`, `bnb_select_node`\n",
    "  - it used to be that the `duals` max heap was automatically purged at the end of the bnb loop (removing FEASIBLE nodes by updating the incumbent and never rescheduling nodes, that were CLOSED)\n",
    "  \n",
    "16. testing feasibility by computing slacks $\\max\\{Ax - b, 0\\}$ to _zero_ is unnecessarily slow\n",
    "\n",
    "17. migrate the code into a python package\n",
    "\n",
    "18. change the order of node and branch selection calls, so as to make the search code more modular\n",
    "\n",
    "19. realize that there is NEVER a need to revisit an earlier branched node: the excluded region cannot contain an integer-feasible solution, even under splits by other variables!\n",
    "20. implemented control inversion (via python threading) for easier experimentation (around the 10th of November, 2022)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37043be",
   "metadata": {},
   "source": [
    "##### References\n",
    "* a well written master thesis on learning to branch [Scavuzzo Montana (2020)](https://repository.tudelft.nl/islandora/object/uuid:e1c09189-0b8f-470f-be99-1e1cf04f805e)\n",
    "* the phd thesis of the core developer of SCIP [Achterberg (2007)](https://depositonce.tu-berlin.de/items/9f46a10e-2f7b-4dea-8e27-9cae07de5258/full)\n",
    "* the original paper that proposes BnB [Benichou et al. (1979)](https://doi.org/10.1007/BF01584074)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b5f7d1",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7969eeea",
   "metadata": {},
   "source": [
    "### on the lp solver backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ccbd52",
   "metadata": {},
   "source": [
    "`linprog` of `scipy.optimize` automatically presolves the problem and resolves redundancies.\n",
    "- we could use it to simplify the search\n",
    "- the parent-child sub-problems be nested __geometrically__, which __does not entail algebraic__ similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3956a7",
   "metadata": {},
   "source": [
    "```python\n",
    "from copy import deepcopy\n",
    "from scipy.optimize._linprog_util import _presolve, _postsolve, _LPProblem\n",
    "    \n",
    "lp = _LPProblem(\n",
    "    p.c, p.A_ub, p.b_ub, p.A_eq, p.b_eq, p.bounds, None\n",
    ")\n",
    "lp_o = deepcopy(lp)\n",
    "\n",
    "# c0 is a constant term in the objective after presolve\n",
    "lp, c0, x, undo, complete, status, message = _presolve(\n",
    "    lp, True, None, tol=1e-9\n",
    ")\n",
    "\n",
    "x, fun, slack, con = _postsolve(\n",
    "    x, (lp_o._replace(bounds=lp.bounds), undo, 1, 1), complete\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edf455c",
   "metadata": {},
   "source": [
    "When the solver is \"highs\" `linprog` from `scipy.optimize` passes the parsed (`_parse_linprog`), but unmodified problem directly to `_linprog_highs`.\n",
    "* it appears that `_getAbc` and other problem transformations are currently undergoing a deprecation cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8955dd31",
   "metadata": {},
   "source": [
    "`_linprog_highs` transforms the problem from $\n",
    "    A_\\mathrm{ub} x \\leq b_\\mathrm{ub}\n",
    "$ to $\n",
    "    -\\infty \\leq A_\\mathrm{ub} x \\leq b_\\mathrm{ub}\n",
    "$ and $\n",
    "    A_\\mathrm{eq} x = b_\\mathrm{eq}\n",
    "$ to $\n",
    "    b_\\mathrm{eq} \\leq A_\\mathrm{eq} x \\leq b_\\mathrm{eq}\n",
    "$.\n",
    "\n",
    "```python\n",
    "from scipy.optimize._linprog_highs import _linprog_highs, _highs_wrapper\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c9fada",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
